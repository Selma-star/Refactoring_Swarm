import os
import glob
from typing import TypedDict, List, Annotated
import operator
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage

# 1. Import the CLASSES (not instances)
from src.agents import Auditor, Fixer, Judge

# 2. Define the State (Shared Memory)
class GraphState(TypedDict):
    messages: Annotated[List[BaseMessage], operator.add]
    target_dir: str
    loop_count: int

# 3. Instantiate your agents (The "Brains")
# We create one instance of each to use throughout the graph
auditor = Auditor()
fixer = Fixer()
judge = Judge()

# Helper function to read code from the target directory
def get_all_code(target_dir: str) -> str:
    code_content = ""
    # Find all .py files in the directory
    files = glob.glob(os.path.join(target_dir, "*.py"))
    for file_path in files:
        with open(file_path, 'r', encoding='utf-8') as f:
            code_content += f"File: {file_path}\n{f.read()}\n\n"
    return code_content

# 4. Define the Nodes

def auditor_node(state: GraphState):
    print("--- üïµÔ∏è Auditor Node ---")
    
    # A. Read the code from disk (because your Auditor class expects a string)
    code_to_analyze = get_all_code(state["target_dir"])
    
    # B. Run your Auditor agent
    # Your agent returns a plain string (the plan)
    plan_text = auditor.run(code_to_analyze)
    
    # C. Wrap the string in an AIMessage so LangGraph can store it
    response = AIMessage(content=plan_text)
    
    return {
        "messages": [response],
        "loop_count": state["loop_count"]
    }

def fixer_node(state: GraphState):
    print("--- üõ†Ô∏è Fixer Node ---")
    
    # The Fixer needs the plan generated by the Auditor.
    # We get the last message from the history.
    last_message = state["messages"][-1]
    plan = last_message.content
    
    # Run your Fixer agent
    # Note: Your fixer class might need the target_dir to write files. 
    # Check if fixer.run() accepts the directory, or if it assumes a hard-coded path.
    # If fixer.run only accepts the plan, we pass just the plan.
    
    # Assuming fixer.run takes the plan and knows where to write (or takes target_dir):
    try:
        # Try passing target_dir if your method supports it, otherwise just plan
        result_text = fixer.run(plan, state["target_dir"])
    except TypeError:
        # If your fixer.run only takes one argument:
        result_text = fixer.run(plan)

    response = AIMessage(content=result_text)
    
    return {
        "messages": [response],
        "loop_count": state["loop_count"]
    }

def judge_node(state: GraphState):
    print("--- ‚öñÔ∏è Judge Node ---")
    
    # Run your Judge agent
    # It likely runs tests and returns "SUCCESS" or "FAIL"
    result_text = judge.run(state["target_dir"])
    
    response = AIMessage(content=result_text)
    
    return {
        "messages": [response],
        "loop_count": state["loop_count"]
    }

# 5. Define the Logic (Conditional Edges)
def should_continue(state: GraphState):
    messages = state["messages"]
    last_message = messages[-1]
    
    # Safety Check: Infinite Loop Protection
    if state["loop_count"] >= 10:
        print("üõë Max iterations reached. Stopping.")
        return "end"

    # Check the Judge's output
    # We look for keywords like "SUCCESS" in the text
    if "SUCCESS" in last_message.content.upper():
        print("‚úÖ Mission accomplished.")
        return "end"
    else:
        print("‚ùå Tests failed. Sending back to Fixer.")
        # Increment the loop count since we are looping
        return "fixer"

# 6. Build the Graph
from langgraph.graph import StateGraph, END

def create_swarm_graph():
    workflow = StateGraph(GraphState)

    workflow.add_node("auditor", auditor_node)
    workflow.add_node("fixer", fixer_node)
    workflow.add_node("judge", judge_node)

    workflow.set_entry_point("auditor")

    workflow.add_edge("auditor", "fixer")
    workflow.add_edge("fixer", "judge")
    
    # If judge says "fixer", go back to fixer. If "end", stop.
    # Note: If we go back to fixer, we should increment loop_count in the transition or node.
    # For simplicity, let's handle loop increment in the edge logic by modifying the node return 
    # or just strictly here (though LangGraph usually expects state updates in nodes).
    # Let's update fixer_node to return loop_count + 1 if we knew we were looping, 
    # but easier: The judge_node or fixer_node should increment it. 
    # Let's modify fixer_node to increment loop_count every time it runs.
    
    # RE-DEFINING FIXER NODE SLIGHTLY TO INCREMENT LOOP:
    global fixer
    original_fixer_node = fixer_node
    def fixer_node_with_count(state):
        result = original_fixer_node(state)
        result["loop_count"] = state["loop_count"] + 1
        return result
    
    workflow.add_node("fixer", fixer_node_with_count)

    workflow.add_conditional_edges(
        "judge",
        should_continue,
        {
            "fixer": "fixer",
            "end": END
        }
    )

    return workflow.compile()